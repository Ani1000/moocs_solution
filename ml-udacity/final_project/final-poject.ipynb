{
 "metadata": {
  "name": "",
  "signature": "sha256:446a97ecd8d2152e23bd7a78073bcbb3f3d1e6292762807e97b77a196098e764"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load poi_id.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/python\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "import sys\n",
      "import pickle\n",
      "sys.path.append(\"../tools/\")\n",
      "\n",
      "from feature_format import featureFormat\n",
      "from feature_format import targetFeatureSplit\n",
      "\n",
      "### features_list is a list of strings, each of which is a feature name\n",
      "### first feature must be \"poi\", as this will be singled out as the label\n",
      "features_list = [\"poi\",\"salary\"]\n",
      "\n",
      "\n",
      "### load the dictionary containing the dataset\n",
      "data_dict = pickle.load(open(\"final_project_dataset.pkl\", \"r\") )\n",
      "\n",
      "### we suggest removing any outliers before proceeding further\n",
      "\n",
      "### if you are creating any new features, you might want to do that here\n",
      "### store to my_dataset for easy export below\n",
      "my_dataset = data_dict\n",
      "\n",
      "\n",
      "\n",
      "### these two lines extract the features specified in features_list\n",
      "### and extract them from data_dict, returning a numpy array\n",
      "data = featureFormat(my_dataset, features_list)\n",
      "\n",
      "\n",
      "\n",
      "### if you are creating new features, could also do that here\n",
      "\n",
      "\n",
      "\n",
      "### split into labels and features (this line assumes that the first\n",
      "### feature in the array is the label, which is why \"poi\" must always\n",
      "### be first in features_list\n",
      "labels, features = targetFeatureSplit(data)\n",
      "\n",
      "\n",
      "\n",
      "### machine learning goes here!\n",
      "### please name your classifier clf for easy export below\n",
      "\n",
      "clf = None    ### get rid of this line!  just here to keep code from crashing out-of-box\n",
      "\n",
      "\n",
      "### dump your classifier, dataset and features_list so \n",
      "### anyone can run/check your results\n",
      "pickle.dump(clf, open(\"my_classifier.pkl\", \"w\") )\n",
      "pickle.dump(data_dict, open(\"my_dataset.pkl\", \"w\") )\n",
      "pickle.dump(features_list, open(\"my_feature_list.pkl\", \"w\") )\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.tree import DecisionTreeClassifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_train,features_test,labels_train,labels_test = \\\n",
      "train_test_split(features,labels,test_size=0.3,random_state=42)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = DecisionTreeClassifier()\n",
      "clf.fit(features_train,labels_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "DecisionTreeClassifier(compute_importances=None, criterion='gini',\n",
        "            max_depth=None, max_features=None, min_density=None,\n",
        "            min_samples_leaf=1, min_samples_split=2, random_state=None,\n",
        "            splitter='best')"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.score(features_test,labels_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "0.72413793103448276"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print precision_score(labels_test,clf.predict(features_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.0\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print recall_score(labels_test,clf.predict(features_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.0\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is the problem of classifier. For this problem, let's see what are the "
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Datasets and Question"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For this problem, to know better about what features to choose and what what kind of algorithm we pick, it's better to get insight of the data to ask series of question. For the first time, we know that by using algorithm identifying whether the person is POI or not, this is the case of classifier. So we may want to try series of classfier algorithm. For now, let's take a look at the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Currently, all the person in the dataset we have"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(data_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "146\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And for the features we have"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(data_dict['SKILLING JEFFREY K'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "21\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_dict['SKILLING JEFFREY K'].keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "['salary',\n",
        " 'to_messages',\n",
        " 'deferral_payments',\n",
        " 'total_payments',\n",
        " 'exercised_stock_options',\n",
        " 'bonus',\n",
        " 'restricted_stock',\n",
        " 'shared_receipt_with_poi',\n",
        " 'restricted_stock_deferred',\n",
        " 'total_stock_value',\n",
        " 'expenses',\n",
        " 'loan_advances',\n",
        " 'from_messages',\n",
        " 'other',\n",
        " 'from_this_person_to_poi',\n",
        " 'poi',\n",
        " 'director_fees',\n",
        " 'deferred_income',\n",
        " 'long_term_incentive',\n",
        " 'email_address',\n",
        " 'from_poi_to_this_person']"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It seems that in dataset, POIs have missing value for their financial value. This could be interpreted wrong by machine, as they tend to guess that for every person that have missing value 'NaN' in financial value, machine would definitely guess POIs. One way to deal with this, is by discard any financial information for Enron employee, and goes straight to use data in Enron email."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}