{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Paired data Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Paired data should have equal number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"confidence interval is\"\n",
      "[1]  9.4868 16.0332\n",
      "[1] \"hypothesis testing is\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] 2.160128e-14"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SL_CI = 0.05\n",
    "\n",
    "n = 73\n",
    "s = 14.26\n",
    "avg_diff = 12.76\n",
    "\n",
    "SE = round(s/sqrt(n),digits=2)\n",
    "z = round(qnorm(SL_CI/2,lower.tail=F),digits=2)\n",
    "\n",
    "print('confidence interval is')\n",
    "ME = z*SE\n",
    "print(c(avg_diff-ME,avg_diff+ME))\n",
    "print('hypothesis testing is')\n",
    "pnorm(avg_diff, mean=0,sd=SE, lower.tail=F) * 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Independence Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"confidence interval is\"\n",
      "[1] 0.6556 4.1444\n",
      "[1] \"hypothesis testing is\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] 1.283454e-46"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = 41.8\n",
    "s_1 = 15.14\n",
    "n_1 = 505\n",
    "\n",
    "x2 = 39.4\n",
    "s_2 = 15.12\n",
    "n_2 = 667\n",
    "\n",
    "\n",
    "pt = x1 - x2\n",
    "SL_CI = 0.05\n",
    "\n",
    "SE = round(sqrt(s_1**2/n_1 + s_2**2/n_2),digits=2)\n",
    "z = round(qnorm(SL_CI/2,lower.tail=F),digits=2)\n",
    "\n",
    "print('confidence interval is')\n",
    "ME = z*SE\n",
    "print(c(pt-ME,pt+ME))\n",
    "print('hypothesis testing is')\n",
    "pnorm(avg_diff, mean=0,sd=SE, lower.tail=F) * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HT** \"If there is no difference of work hours on average between college degree vs non college degree, there is 0.7% chance of obtaining random samples of 505 college and 667 non-college degree give average difference of work hours at least 2.4 hours\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jpeg](../galleries/coursera-statistics/4w10.jpg)\n",
    "\n",
    "\n",
    "*Screenshot taken from [Coursera](https://class.coursera.org/statistics-003/lecture/99) 03:46*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jpeg](../galleries/coursera-statistics/4w16.jpg)\n",
    "\n",
    "\n",
    "*Screenshot taken from [Coursera](https://class.coursera.org/statistics-003/lecture/99) 12:14*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]  735.6105 1029.4195"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#95% = 1.96\n",
    "#99% = 2.58\n",
    "\n",
    "n = 100\n",
    "mu = 882.515\n",
    "# s = 89.5758\n",
    "# z = 1.96\n",
    "CL = 0.9\n",
    "z = round(qnorm((1-CL)/2,lower.tail=F),digits=2)\n",
    "# SE = s/sqrt(n)\n",
    "SE = 89.5759\n",
    "ME = z*SE\n",
    "\n",
    "\n",
    "c(mu-ME,mu+ME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* samping distritbuion with replacement from population, where bootsrap with replacement from sample\n",
    "* Both are distributions of sample statistics. CLT can explicitly describe the distribution of the population, where bootstrap also describe that using one sample.\n",
    "\n",
    "Bootstrap can be created by using with replacement in one sample. This is different from sampling distribution, where it takes with replacement from population.We can use percentile method; take 100 sample size bootstrap and cut off the sided for XX% interval, or calculate percentile based on the known condition that the distribution is normal, use point estimate bootstrap and standard error bootstrap.There's one weakness of bootstrap, is that when you have skew and sparse bootstrap distribution, it's not reliable.\n",
    "\n",
    "Paired data, is when you have one observation dependent on other variable.We can use these set differences as a basis to use hypothesis testing and confidence interval. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jpeg](../galleries/coursera-statistics/4w25.jpg)\n",
    "\n",
    "\n",
    "*Screenshot taken from [Coursera](https://class.coursera.org/statistics-003/lecture/105) 03:42*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**t-distribution** can be two-sided test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-distribution is used when we have small sample size, less than 30. We use single parameter, degree of freedom to mitigate poor standard of error. We also verify that eventhough sample size is small, it's less than 10% population, and verify that the outliers it not too extreme(below two standard deviation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating t-score that is 1.65 standard deviation away, with degree of freedom 20. Looking for outer tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] 0.3117426"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=17\n",
    "#NOT POINT ESTIMATE, BUT T-STATISTIC\n",
    "t_statistic = 0.5\n",
    "pt(t_statistic,df=df,lower.tail=F)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given confidence interval/significance level, and degree of freedom. find the cut off value, which is always positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] 2.100922"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CL = 0.95\n",
    "n = 19\n",
    "qt((1-CL)/2, df=n-1,lower.tail=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] 3.105807"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CL = 0.99\n",
    "n = 12\n",
    "qt((1-CL)/2, df=n-1,lower.tail=F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jpeg](../galleries/coursera-statistics/4w23.jpg)\n",
    "\n",
    "\n",
    "*Screenshot taken from [Coursera](https://class.coursera.org/statistics-003/lecture/103) 09:57*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jpeg](../galleries/coursera-statistics/4w24.jpg)\n",
    "\n",
    "\n",
    "*Screenshot taken from [Coursera](https://class.coursera.org/statistics-003/lecture/103) 15:49*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Hypothesis Testing is \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] 0.01900261"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Confidence Interval is \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] 52.9 59.1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbar = 56\n",
    "mu = 0\n",
    "sd = 8\n",
    "n = 20\n",
    "CL = 0.9\n",
    "\n",
    "\n",
    "SE = round(sd/sqrt(n),digits=2)\n",
    "t_star = round((xbar-mu)/SE,digits=2)\n",
    "z = round(qt ((1-CL)/2,lower.tail=F,df=n-1),digits=2)\n",
    "\n",
    "\n",
    "print('Hypothesis Testing is ')\n",
    "\n",
    "\n",
    "pt(t_star, df=n-1, lower.tail=xbar < mu)\n",
    "print('Confidence Interval is ')\n",
    "ME = round(z*SE, digits=2)\n",
    "c(xbar-ME,xbar+ME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] -1.8"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since null hypothesis is not in the interval, CI agrees with HT in this case. Rejecting the null hypothesis, must be that null value not in the confidence interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Two Means with t-distribution (small sample size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"confidence interval is\"\n",
      "[1]  1.8288 48.1712\n",
      "[1] \"hypothesis testing is\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] 4.150183e-17"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = 52.1\n",
    "s_1 = 45.1\n",
    "n_1 = 22\n",
    "\n",
    "x2 = 27.1\n",
    "s_2 = 26.4\n",
    "n_2 = 22\n",
    "\n",
    "\n",
    "avg_diff =  x1-x2\n",
    "SL_CI = 0.02\n",
    "\n",
    "SE = round(sqrt(s_1**2/n_1 + s_2**2/n_2),digits=2)\n",
    "z = round(qt(SL_CI/2,df=min(n_1-1,n_2-1),lower.tail=F),digits=2)\n",
    "\n",
    "print('confidence interval is')\n",
    "ME = z*SE\n",
    "print(c(avg_diff-ME,avg_diff+ME))\n",
    "print('hypothesis testing is')\n",
    "# pnorm(avg_diff, mean=0,sd=SE, lower.tail=F) * 2\n",
    "pt(avg_diff, df=min(n_1-1,n_2-1),lower.tail=avg_diff < 0) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"confidence interval is\"\n",
      "[1] -3.0728 53.0728\n",
      "[1] \"hypothesis testing is\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] 4.150183e-17"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = 52.1\n",
    "s_1 = 45.1\n",
    "n_1 = 22\n",
    "\n",
    "x2 = 27.1\n",
    "s_2 = 26.4\n",
    "n_2 = 22\n",
    "\n",
    "\n",
    "avg_diff =  x1-x2\n",
    "SL_CI = 0.02\n",
    "\n",
    "SE = round(sqrt(s_1**2/n_1 + s_2**2/n_2),digits=2)\n",
    "z = round(qt(SL_CI/2,df=min(n_1-1,n_2-1),lower.tail=F),digits=2)\n",
    "\n",
    "print('confidence interval is')\n",
    "ME = z*SE\n",
    "print(c(avg_diff-ME,avg_diff+ME))\n",
    "print('hypothesis testing is')\n",
    "# pnorm(avg_diff, mean=0,sd=SE, lower.tail=F) * 2\n",
    "pt(avg_diff, df=min(n_1-1,n_2-1),lower.tail=avg_diff < 0) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"confidence interval is\"\n",
      "[1] 0.9236 6.0764\n",
      "[1] \"hypothesis testing is\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] 0.006723516"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = 248.3\n",
    "s_1 = 2\n",
    "n_1 = 10\n",
    "\n",
    "x2 = 244.8\n",
    "s_2 = 3\n",
    "n_2 = 10\n",
    "\n",
    "\n",
    "avg_diff =  x1-x2\n",
    "SL_CI = 0.05\n",
    "\n",
    "# SE = round(sqrt(s_1**2/n_1 + s_2**2/n_2),digits=2)\n",
    "\n",
    "spooled = ((s_1**2*(n_1-1)) + (s_2**2*(n_2-1))) / (n_1+n_2-2)\n",
    "\n",
    "SE = round(sqrt(spooled/n_1 + spooled/n_2),digits=2)\n",
    "\n",
    "z = round(qt(SL_CI/2,df=min(n_1-1,n_2-1),lower.tail=F),digits=2)\n",
    "\n",
    "print('confidence interval is')\n",
    "ME = z*SE\n",
    "print(c(avg_diff-ME,avg_diff+ME))\n",
    "print('hypothesis testing is')\n",
    "# pnorm(avg_diff, mean=0,sd=SE, lower.tail=F) * 2\n",
    "pt(avg_diff, df=min(n_1-1,n_2-1),lower.tail=avg_diff < 0) * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can say that we are 95% confident those with eating distractions consume between 1.83 to 48.17 grams more snack to those without distractions, on average.Since null value is not within the interval, CI agrees with HT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplify the calculation if population sd of two groups is similar\n",
    "\n",
    "![jpeg](../galleries/coursera-statistics/4w60.jpg)\n",
    "\n",
    "\n",
    "*Screenshot taken from [Coursera](https://class.coursera.org/statistics-003/lecture/105) 08:39*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* the observations should be independent within and across groups\n",
    "* the data within each group are nearly normal \n",
    "* the variability across the groups is about equal and use graphical diagnostics to check if these conditions are met. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recognize that the test statistic for ANOVA, the F statistic, is calculated as the ratio of the mean square between groups (MSG, variability between groups) and mean square error (MSE, variability within errors). Also recognize that the F statistic has a right skewed distribution with two different measures of degrees of freedom: one for the numerator (dfG=k−1, where k is the number of groups) and one for the denominator (dfE=n−k, where n is the total sample size). \n",
    "Note that you won’t be expected to calculate MSG or MSE from the raw data, but you should have a conceptual understanding of how they’re calculated and what they measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jpeg](../galleries/coursera-statistics/4w37.jpg)\n",
    "\n",
    "\n",
    "*Screenshot taken from [Coursera](https://class.coursera.org/statistics-003/lecture/107) 08:42*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F-statistics in ANOVA, larger means smaller p-value.Positive skewed because the variability between groups and among groups can never be negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] 1.559855e-13"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_group = 4\n",
    "n_total = 795\n",
    "f_value = 21.735\n",
    "dfg = n_group -1\n",
    "dft = n_total - 1\n",
    "dfe = dft - dfg\n",
    "\n",
    "pf(f_value,dfg,dfe,lower.tail=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] 0.0315703"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_group = 3\n",
    "n_total = 831\n",
    "f_value = 3.47\n",
    "dfg = n_group -1\n",
    "dft = n_total - 1\n",
    "dfe = dft - dfg\n",
    "\n",
    "pf(f_value,dfg,dfe,lower.tail=F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpret ANOVA**,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If p-value < $\\alpha$, the data provide convincing evidence that at least one pair of population are different from each other (we can't tell which one).In this case we reject the null hypothesis.\n",
    "\n",
    "If p-value > $\\alpha$, the data doesn't provide convincing evidence that one pair of population means are different from each other, the observed difference is due to sampling variability(or by chance).In this case we fail to reject null hypothesis.\n",
    "\n",
    "Since p-value is really small in this problem, we reject the null hypothesis, and conclude that the data is provide convincing evidence that at least one pair of population means are different from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Benferroni Correction** Where you want to modify significance level, to adapt with changing type 1 error. After you reject null hypothesis using ANOVA, you want to test which of the pair is contribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] 0.002380952"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "k = 7\n",
    "SL = 0.05\n",
    "\n",
    "SL/((k*(k-1))/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jpeg](../galleries/coursera-statistics/4w54.jpg)\n",
    "\n",
    "\n",
    "*Screenshot taken from [Coursera](https://class.coursera.org/statistics-003/lecture/113) 08:19*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] 1.09828e-07"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1 = 6.76\n",
    "n_1 = 331\n",
    "\n",
    "x_2 = 5.07\n",
    "n_2 = 41\n",
    "\n",
    "MSE = 3.628\n",
    "df_res = 791\n",
    "null=0\n",
    "\n",
    "T = (x_1-x_2-null)/sqrt(MSE/n_1+MSE/n_2)\n",
    "\n",
    "2*pt(T,df_res,lower.tail=F)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore we reject the null hypothesis, and the data provide convincing evidence that average of vocabulary scores between self-reported middle and lower class Americans are different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANOVA is statiscal tools that lets you analyze many groups at once. Is it due to chance variability of particular groups compared to variability of others? Different from usual HT, in ANOVA you set null hypothesis to be equal means across groups. But in alternative, you want to observe at least one group is different. Two probability, either all equal, or at least one different.\n",
    "\n",
    "Conditions for ANOVA is at independence for between groups and within groups. The distribution of each group is nearly normal, and you variability across groups also nearly normal.  Use graphical tools like boxplot and summary statistics to make intuition about the data. F-statistic will be get by calculating MSG with MSE, the means will calculated by dividing the sum of squares with its corresponding degree of freedom.This is right skewed distribution, you won't be have negative number, which always yield positive number. Therefore we always use one sided p-value.\n",
    "\n",
    "Recall that we have 5% type 1 error rate for one hypothesis test. Doing multiple test will pile up the error, so fix number of 5% is not enough. We have to always push down the error rate, and by doing that incorporate with K-value.It's possible that when you reject the null hypothesis(statiscally significant) in ANOVA, but end up not finding it when you test it between groups. Remember that ANOVA is about at least one is different. And you may only one group that is different, but not for the rest of the groups. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the standard error,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqrt(0.08*(1-0.08)/125)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using, binomial, calculate the probability of success at least 190 out of 200, given that proportion of success is 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum(dbinom(190:200,200,0.90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] 1.378061e-96"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dbinom(100:131,100,0.11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] 600.25"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Required sample size proportion for desired ME\n",
    "\n",
    "SL_CI = 0.95\n",
    "p = 0.5\n",
    "z_star = 1.96\n",
    "ME = 0.04\n",
    "z = round(qnorm((1-SL_CI)/2,lower.tail=F),digits=2)\n",
    "\n",
    "\n",
    "z**2*p*(1-p)/ME**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "observed the likelihood of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "In dbinom(30 * 0.12, 250, 0.08): non-integer x = 3.600000"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] 0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbinom(30*0.12,250,0.08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jpeg](../galleries/coursera-statistics/5w12.jpg)\n",
    "\n",
    "\n",
    "*Screenshot taken from [Coursera](https://class.coursera.org/statistics-003/lecture/119) 04:33*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Confidence Interval is \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] 0.15432 0.18568"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Hypothesis Testing is \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] 6.558556e-98"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 2254\n",
    "p = 0.17\n",
    "CL = 0.95\n",
    "p_pop = 0.38\n",
    "\n",
    "z_star = round(qnorm((1-CL)/2, lower.tail=F),digits=2)\n",
    "\n",
    "print('Confidence Interval is ')\n",
    "SE_CI = round(sqrt(p*(1-p)/n),digits=3)\n",
    "ME = z_star*SE_CI\n",
    "c(p-ME, p+ME)\n",
    "print('Hypothesis Testing is ')\n",
    "SE_HT = round(sqrt((p_pop*(1-p_pop)/n)),digits=3)\n",
    "pnorm(p, mean=p_pop,sd=SE_HT, lower.tail=p < p_pop) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Confidence Interval is \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] 0.2252608 0.2547392"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Hypothesis Testing is \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] 1.332703e-08"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 3226\n",
    "p = 0.24\n",
    "CL = 0.95\n",
    "p_pop = 0.2\n",
    "\n",
    "z_star = round(qnorm((1-CL)/2, lower.tail=F),digits=2)\n",
    "\n",
    "print('Confidence Interval is ')\n",
    "SE_CI = round(sqrt(p*(1-p)/n),digits=5)\n",
    "ME = z_star*SE_CI\n",
    "c(p-ME, p+ME)\n",
    "print('Hypothesis Testing is ')\n",
    "SE_HT = round(sqrt((p_pop*(1-p_pop)/n)),digits=5)\n",
    "pnorm(p, mean=p_pop,sd=SE_HT, lower.tail=p < p_pop) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] 0.00704"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SE_HT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] 0.00752"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SE_CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in pnorm(4, mean = 0.11, df = 99, lower.tail = F): unused argument (df = 99)\n",
     "output_type": "error",
     "traceback": [
      "Error in pnorm(4, mean = 0.11, df = 99, lower.tail = F): unused argument (df = 99)\n"
     ]
    }
   ],
   "source": [
    "pnorm(4,mean=0.11,df=99,lower.tail=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] 0.06128364"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbinom(7,100,0.11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] 600.25"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Required sample size proportion for desired ME\n",
    "\n",
    "SL_CI = 0.95\n",
    "p = 0.5\n",
    "z_star = 1.96\n",
    "ME = 0.04\n",
    "z = round(qnorm((1-SL_CI)/2,lower.tail=F),digits=2)\n",
    "\n",
    "\n",
    "z**2*p*(1-p)/ME**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] 600.25"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Required sample size proportion for desired ME\n",
    "\n",
    "SL_CI = 0.95\n",
    "p = 0.11\n",
    "z_star = 1.96\n",
    "ME = 0.04\n",
    "z = round(qnorm((1-SL_CI)/2,lower.tail=F),digits=2)\n",
    "\n",
    "\n",
    "z**2*p*(1-p)/ME**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Confidence Interval is \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] -0.25328  0.01328"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"p-value for hypothesis test is\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] 0.08201182"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_1 = 90\n",
    "p_1 = 0.38\n",
    "\n",
    "n_2 = 122\n",
    "p_2 = 0.5\n",
    "\n",
    "CL = 0.95\n",
    "\n",
    "avg_diff = p_1-p_2\n",
    "\n",
    "\n",
    "z_star = round(qnorm((1-CL)/2, lower.tail=F),digits=2)\n",
    "p_population = 0.3\n",
    "p_pool = round((p_1*n_1+p_2*n_2)/(n_1+n_2),digits=2)\n",
    "p_population = p_pool\n",
    "null = 0\n",
    "\n",
    "\n",
    "print('Confidence Interval is ')\n",
    "SE_CI = round(sqrt((p_1*(1-p_1)/n_1)+(p_2*(1-p_2)/n_2)),digits=3)\n",
    "ME = z_star*SE_CI\n",
    "c((p_1-p_2)-ME, (p_1-p_2)+ME)\n",
    "print('p-value for hypothesis test is')\n",
    "#ONE SIDED OR TWO SIDED?\n",
    "SE_HT = round(sqrt((p_population*(1-p_population)/n_1)+(p_population*(1-p_population)/n_2)),digits=3)\n",
    "pnorm(avg_diff, mean=null,sd=SE_HT, lower.tail=avg_diff < null) * 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Confidence Interval is \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] 0.23296 0.32704"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"p-value for hypothesis test is\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] 4.077335e-29"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_1 = 819\n",
    "p_1 = 0.7\n",
    "\n",
    "n_2 = 783\n",
    "p_2 = 0.42\n",
    "\n",
    "CL = 0.95\n",
    "\n",
    "avg_diff = p_1-p_2\n",
    "\n",
    "\n",
    "z_star = round(qnorm((1-CL)/2, lower.tail=F),digits=2)\n",
    "# p_population = 0.3\n",
    "p_pool = round((p_1*n_1+p_2*n_2)/(n_1+n_2),digits=2)\n",
    "p_population = p_pool\n",
    "null = 0\n",
    "\n",
    "\n",
    "print('Confidence Interval is ')\n",
    "SE_CI = round(sqrt((p_1*(1-p_1)/n_1)+(p_2*(1-p_2)/n_2)),digits=3)\n",
    "ME = z_star*SE_CI\n",
    "c((p_1-p_2)-ME, (p_1-p_2)+ME)\n",
    "print('p-value for hypothesis test is')\n",
    "#ONE SIDED OR TWO SIDED?\n",
    "SE_HT = round(sqrt((p_population*(1-p_population)/n_1)+(p_population*(1-p_population)/n_2)),digits=3)\n",
    "pnorm(avg_diff, mean=null,sd=SE_HT, lower.tail=avg_diff < null) * 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] -0.14718610 -0.06152731"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_1 = 120\n",
    "p_1 = 493/n_1\n",
    "\n",
    "n_2 = 1028\n",
    "p_2 = 596/n_2\n",
    "\n",
    "\n",
    "\n",
    "CL = 0.95\n",
    "\n",
    "SE = sqrt(   (p_1*(1-p_1)/n_1)+(p_2*(1-p_2)/n_2)   )\n",
    "z_star = round(qnorm((1-CL)/2, lower.tail=F),digits=2)\n",
    "ME = z_star*SE\n",
    "\n",
    "c((p_1-p_2)-ME, (p_1-p_2)+ME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the p-value and 5% significance level, we would failed to reject null hypothesis, and states **there is no difference between males and females with respect to likelihood reporting their kids to being bullied**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When defining population proportion, you use p. When you define sample proportion, you use $\\hat{p}$. Plug population proportion to standard error formula. But since it almost always not known, use sample proportion.\n",
    "\n",
    "For proportion, CLT states that the distribution of sample distribution will be nearly normal, centered at the true population proportion,with standard error as long as:\n",
    "    * Observations in the sample are independent to one another.\n",
    "    * At least 10 expected success and 10 expected failures in the observations.\n",
    "\n",
    "For confidence interval, we use sampled proportion (if we already know the true population proportion, it's useless to build an interval to capture it). For hypothesis testing, we have true population,and incorporate it to our standard error calculation.For numerical variable, standard error doesn't incorporate mean, it uses standard deviation. So it doesn't have discrepancy for computing confidence interval and hypothesis testing.\n",
    "\n",
    "When calculating required sample size for particular margin of error, if sampled proportion is unknown, we use 0.5. This have advantage in two ways. First, if categorical variable only have two levels, we have fair judgement, best prior uniform. Second, 0.5 will gives us the largest sample size.\n",
    "\n",
    "\n",
    "Calculating for standard error of two categorical variable, testing the difference, is different when we have confidence interval or hypothesis testing that have null value other than zero. We join standard error of both propotion of categorical variable. But for hypothesis testing that have null value zero, both of categorical variable proportion is not known. Hence we use pool proportion, joining successes divided by sample size of both categorical variables. The reason behind another discrepancy for hypothesis testing with null value zero, is that assumed that proportions are equal for levels in categorical variable, we have to use common proportions that fit both levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make **inference based on simulation**. **If success and failure condition is not met**\n",
    "\n",
    "* The focus here is the p-value. Remember p-value is probability of observing at least as favorable to the outcome given the null hypothesis is true.\n",
    "* Devise the simulation that assumes null hypothesis is true. Since we have two mutually exclusive outcome, we can use head/tail of fair coin(use fair because we assume null hypothesis is true, proportions are equal). So we flip coin 8 times and record the proportion of heads come out(success).\n",
    "* Repeat the simulation of N-times takes record relevant sample statistics, in this case the proportion.\n",
    "* Calculate p-value as the probability of at least favorable to the observed outcome. What is the probability that the proportions of heads is at least as an observed outcome. So what are the probability that simulations head comes at least 8 times. Remember that proportion hat is correctly guess of all 8 times, so the p hat is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Focusing on one level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Confidence Interval is \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] 0.35808 0.56192"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"p-value for hypothesis test is\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] 4.529368e-19"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_1 = 83\n",
    "p_1 = 0.71\n",
    "\n",
    "n_2 = 1028\n",
    "p_2 = 0.25\n",
    "\n",
    "CL = 0.95\n",
    "\n",
    "avg_diff = p_1-p_2\n",
    "\n",
    "SE = round(sqrt((p_1*(1-p_1)/n_1)+(p_2*(1-p_2)/n_2)),digits=3)\n",
    "z_star = round(qnorm((1-CL)/2, lower.tail=F),digits=2)\n",
    "ME = z_star*SE\n",
    "\n",
    "print('Confidence Interval is ')\n",
    "c((p_1-p_2)-ME, (p_1-p_2)+ME)\n",
    "print('p-value for hypothesis test is')\n",
    "#ONE SIDED OR TWO SIDED?\n",
    "pnorm(avg_diff, mean=0.0,sd=SE, lower.tail=avg_diff < 0.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**we are 95% confident that proportion of Courserians is 36% to 56% higher than US that believe there should be law for banning gun possesion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Square Independence Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jpeg](../galleries/coursera-statistics/5w49.jpg)\n",
    "\n",
    "\n",
    "*Screenshot taken from [Coursera](https://class.coursera.org/statistics-003/lecture/159) 03:53*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jpeg](../galleries/coursera-statistics/5w50.jpg)\n",
    "\n",
    "\n",
    "*Screenshot taken from [Coursera](https://class.coursera.org/statistics-003/lecture/159) 06:55*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using chi-square to calculate the p-value, given degree of freedom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] 1.320613e-07"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Given chisquare statistic and degree of freedom, compute the chi-square\n",
    "\n",
    "pchisq(31.68,2,lower.tail=F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Square GOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Expected cell size at least 5\n",
    "* chi-square is the same, except with GOF, df is (n_cells-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Square Independence Test\n",
    "\n",
    "* Expected counts for each cell at least 5\n",
    "* Degree of freedom calculated is more than 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "\n",
    "Chi-square GOF test one single categorical variable whether it follows hypothesized distribution or not. Null hypothesis states that the observed proportion follows population proportion, and there isn't something going on. On the other hand,alternative hypothesis states the observed proportion doesn't follow population proportion, and there is indeed something going on.For one way table, we can calculate expected counts for each cell, by sample sized times each of proportion in hypothesized distribution.\n",
    "\n",
    "We can calculate chi-square statistics by calculate the difference of observed and expected squared, divided by expected, and sum all of the cells. For one categorical variable, degree of freedom can be calculated by k-1, as k is the number of groups. For two categorical variable, dof calculated as (R-1)x(C-1) where R is number of rows, and C is number of columns.\n",
    "\n",
    "The conditions for both chisquare GOF and independence test, is that observations are independent of one another. The expected counts for each cell is at least 5. And degree of freedom is at least two(more than 2 levels outcome). If this condition is not met, we use other methods, such as evaluating proportions.We then calculate each cell incorporate it into chi-square statistic, then using the statistics, degree of freedom and lower tail false to obtain p-value.\n",
    "\n",
    "For chi-square independence test, we test two categorical variables, whether they independent or dependent of one another. We can't use confidence intervals for this problem, since we observe both variables with many levels(not observe one level in one of the variables). If p-value is above significance level, we failed to reject null hypothesis, and conclude that the data provide strong evidence that both categorical variables are indeed dependent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] 3.75"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"The intercept is \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] 51.318"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating the slope for x\n",
    "sy = 5\n",
    "sx = 4\n",
    "# mx - \n",
    "R = 3\n",
    "\n",
    "#To calculate the slope....\n",
    "sy/sx*R\n",
    "\n",
    "#formula for linear regression\n",
    "#y-yo = slope(x-xo) where xo/yo is the mean\n",
    "#Finding the intercept\n",
    "slope = 0.726\n",
    "x = 107\n",
    "y = 129\n",
    "print('The intercept is ')\n",
    "y - slope*x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When observing the relationship, observe on:\n",
    "\n",
    "* Linear/not?\n",
    "* Strong/Weak?\n",
    "* Positive/Negative?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* See the sign of correlation by looking at the direction trend of the data.\n",
    "* Interpreting the residuals : There are 6.14% more bike riders wearing helment  than predicted by the model in this neighborhhood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] 0.7107336"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating adjusted R squared\n",
    "\n",
    "var_e = 23.34\n",
    "var_y = 83.06\n",
    "n = 141\n",
    "k = 4\n",
    "\n",
    "1 - var_e/var_y * (n-1)/(n-k-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"R Squared is \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] 0.7466686"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Adjusted R squared is \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] 0.7383284"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating adjusted R squared\n",
    "\n",
    "var_e = 3819.99\n",
    "var_y = 15079.02\n",
    "n = 252\n",
    "k = 8\n",
    "\n",
    "print('R Squared is ')\n",
    "1 - var_e/var_y\n",
    "\n",
    "print('Adjusted R squared is ')\n",
    "1 - var_e/var_y * (n-1)/(n-k-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] -0.3152  0.1552"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CI MLR\n",
    "\n",
    "CL = 0.95\n",
    "SE = 0.12\n",
    "pt = -0.08\n",
    "\n",
    "z = round(qnorm((1-CL)/2,lower.tail=F),digits=2)\n",
    "\n",
    "ME = z*SE\n",
    "c(pt-ME,pt+ME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you should validate the conditions for MLR. \n",
    "\n",
    "* You want each numerical to have linearity with the response, and validate that residuals are random scatter around zero, constant variability, normally distributed, and each is independent of one another.\n",
    "* Scatter plot each numerical and residuals, check linearity.\n",
    "* Histogram or probability plot to check residuals distribution normal\n",
    "* Scatter plot residuals-predicted, check residuals constant variability.\n",
    "* Scatter plot residuals-index check residuals is independent of one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
